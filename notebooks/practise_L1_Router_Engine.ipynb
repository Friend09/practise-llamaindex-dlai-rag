{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='2beb6959-9b90-4943-a50f-a83c2c3e738e', embedding=None, metadata={'page_label': '1', 'file_name': 'metagpt.pdf', 'file_path': '../files/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-08', 'last_modified_date': '2024-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preprint\\nMETAGPT: M ETA PROGRAMMING FOR A\\nMULTI -AGENT COLLABORATIVE FRAMEWORK\\nSirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\\nCeyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\\nLiyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\\n1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\\n3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\\n5Nanjing University,6University of Pennsylvania,\\n7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\\nABSTRACT\\nRemarkable progress has been made on automated problem solving through so-\\ncieties of agents based on large language models (LLMs). Existing LLM-based\\nmulti-agent systems can already solve simple dialogue tasks. Solutions to more\\ncomplex tasks, however, are complicated through logic inconsistencies due to\\ncascading hallucinations caused by naively chaining LLMs. Here we introduce\\nMetaGPT, an innovative meta-programming framework incorporating efficient\\nhuman workflows into LLM-based multi-agent collaborations. MetaGPT en-\\ncodes Standardized Operating Procedures (SOPs) into prompt sequences for more\\nstreamlined workflows, thus allowing agents with human-like domain expertise\\nto verify intermediate results and reduce errors. MetaGPT utilizes an assembly\\nline paradigm to assign diverse roles to various agents, efficiently breaking down\\ncomplex tasks into subtasks involving many agents working together. On col-\\nlaborative software engineering benchmarks, MetaGPT generates more coherent\\nsolutions than previous chat-based multi-agent systems. Our project can be found\\nat https://github.com/geekan/MetaGPT.\\n1 I NTRODUCTION\\nAutonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\\nhance and replicate human workflows. In real-world applications, however, existing systems (Park\\net al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\\nLiang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\\neffective, coherent, and accurate problem-solving processes, particularly when there is a need for\\nmeaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\\net al., 2023; Qian et al., 2023).\\nThrough extensive collaborative practice, humans have developed widely accepted Standardized\\nOperating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\\nLister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\\ndination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\\nstandards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\\ncution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\\nDeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\\nProduct Managers analyze competition and user needs to create Product Requirements Documents\\n(PRDs) using a standardized structure, to guide the developmental process.\\nInspired by such ideas, we design a promising GPT -based Meta -Programming framework called\\nMetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\\n2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\\n∗These authors contributed equally to this work.\\n†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\\n1', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='657c3932-1214-450c-a931-8fb3bef94651', embedding=None, metadata={'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': '../files/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-08', 'last_modified_date': '2024-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preprint\\nFigure 1: The software development SOPs between MetaGPT and real-world human teams.\\nIn software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\\nits ability to decompose complex tasks into specific actionable procedures assigned to various roles\\n(e.g., Product Manager, Architect, Engineer, etc.).\\ndocuments, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\\ntured outputs significantly increases the success rate of target code generation. Because it helps\\nmaintain consistency in communication, minimizing ambiguities and errors during collaboration.\\nMore graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\\nlined workflow, and all their handovers must comply with certain established standards. This reduces\\nthe risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\\nworks, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\\nlunch?” – Bob (Architect).\\nBenefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\\nwe adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\\nlearning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\\n2006; Finn et al., 2017).\\nThis notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\\n2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\\net al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\\nprogramming through a well-organized group of specialized agents. Each agent has a specific role\\nand expertise, following some established standards. This allows for automatic requirement analysis,\\nsystem design, code generation, modification, execution, and debugging during runtime, highlight-\\ning how agent-based techniques can enhance meta-programming.\\nTo validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\\nMBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\\nachieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\\npopular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\\n2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\\nMetaGPT also stands out in handling higher levels of software complexity and offering extensive\\nfunctionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\\npletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\\nWe summarize our contributions as follows:\\n1https://en.wikipedia.org/w/index.php?title=Metaprogramming\\n2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"../files/metagpt.pdf\"]).load_data()\n",
    "documents[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define llms - OPENAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define llms - OLLAMA\n",
    "\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"llama3:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "# pass_embedding = ollama_embedding.get_text_embedding_batch(\n",
    "#     [\"This is a passage!\", \"This is another passage\"], show_progress=True\n",
    "# )\n",
    "# print(pass_embedding)\n",
    "\n",
    "# query_embedding = ollama_embedding.get_query_embedding(\"Where is blue?\")\n",
    "# print(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk documents into sentence nodes\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex  # index -> Embeddings\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE QUERY ENGINE & SET METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"Useful for summarization questions related to MetaGPT\"),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\"Useful for retrieving specific context from MetaGPT paper.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUTER ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: This choice indicates that the document is useful for summarization questions related to MetaGPT..\n",
      "\u001b[0mThe document introduces MetaGPT, a meta-programming framework that enhances the problem-solving capabilities of multi-agent systems based on Large Language Models (LLMs) by incorporating human-like Standard Operating Procedures (SOPs). MetaGPT assigns specific roles to agents, streamlines workflows, and improves communication efficiency. It focuses on role specialization, workflow organization, structured communication interfaces, and executable feedback mechanisms to enhance code generation quality during runtime. Through extensive experiments, MetaGPT demonstrates superior performance on various benchmarks, outperforming existing approaches. The document also discusses the development process using MetaGPT for software projects, highlighting the structured approach from user input commands to system design. Additionally, it delves into the performance of different GPT models, ethical concerns, design challenges, and the handling of information overload by MetaGPT.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context from the MetaGPT paper, which aligns with the request to get the list of all sections of the document..\n",
      "\u001b[0mThe sections of this document are as follows:\n",
      "1. Figure 12: The program call flow for “recommendation engine development” generated by the architect agent\n",
      "2. Figure 3: A diagram showing the software development process in MetaGPT\n",
      "3. Communication Protocol\n"
     ]
    }
   ],
   "source": [
    "print(query_engine.query(\"get me the list of all sections of this document\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
